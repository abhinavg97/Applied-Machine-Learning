{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing necessary modules\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import sklearn.preprocessing as skp\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same as defined in \"CS15BTECH11044_svm\"\n",
    "list_columns = [\"age\",\"workclass\",\"fnlgwt\",\"education\",\"education_num\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital_gain\",\"capital_loss\",\"hours_per_week\",\"native_country\",\"target\"]\n",
    "discrete = [\"workclass\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native_country\"]\n",
    "dict_columns = {}\n",
    "for i,name in enumerate(list_columns):\n",
    "    dict_columns[name] = i\n",
    "dict_workclass = {\"Private\":0, \"Self-emp-not-inc\":1, \"Self-emp-inc\":2, \"Federal-gov\":3, \"Local-gov\":4, \"State-gov\":5, \"Without-pay\":6, \"Never-worked\":7}\n",
    "dict_education = {\"Bachelors\":0, \"Some-college\":1, \"11th\":2, \"HS-grad\":3, \"Prof-school\":4, \"Assoc-acdm\":5, \"Assoc-voc\":6, \"9th\":7, \"7th-8th\":8, \"12th\":9, \"Masters\":10, \"1st-4th\":11, \"10th\":12, \"Doctorate\":13,\"5th-6th\":14,\"Preschool\":15}\n",
    "dict_marry = {\"Married-civ-spouse\":0, \"Divorced\":1, \"Never-married\":2, \"Separated\":3, \"Widowed\":4, \"Married-spouse-absent\":4, \"Married-AF-spouse\":5}\n",
    "dict_occ = {\"Tech-support\":0, \"Craft-repair\":1, \"Other-service\":2, \"Sales\":3, \"Exec-managerial\":4, \"Prof-specialty\":5, \"Handlers-cleaners\":6, \"Machine-op-inspct\":7, \"Adm-clerical\":8, \"Farming-fishing\":9, \"Transport-moving\":10, \"Priv-house-serv\":11, \"Protective-serv\":12, \"Armed-Forces\":13}\n",
    "dict_relation = {\"Wife\":0, \"Own-child\":1, \"Husband\":2, \"Not-in-family\":3, \"Other-relative\":4, \"Unmarried\":5}\n",
    "dict_race = {\"White\":0, \"Asian-Pac-Islander\":1, \"Amer-Indian-Eskimo\":2, \"Other\":3, \"Black\":4}\n",
    "dict_sex = {\"Female\":0,\"Male\":1}\n",
    "dict_native_country = {\"France\":0,\"United-States\":1,\"Cambodia\":2,\"England\":3,\"Puerto-Rico\":4,\"Canada\":5,\"Germany\":6,\"Outlying-US(Guam-USVI-etc)\":7,\"India\":8,\"Japan\":9,\"Greece\":10,\"South\":11,\"China\":12,\"Cuba\":13,\"Iran\":14,\"Honduras\":15,\"Philippines\":16,\"Italy\":17,\"Poland\":18,\"Jamaica\":19,\"Vietnam\":20,\"Mexico\":21,\"Portugal\":22,\"Ireland\":23,\"Dominican-Republic\":24,\"Laos\":25,\"Ecuador\":26,\"Taiwan\":27,\"Haiti\":28,\"Columbia\":29,\"Hungary\":30,\"Guatemala\":31,\"Nicaragua\":32,\"Scotland\":33,\"Thailand\":34,\"Yugoslavia\":35,\"El-Salvador\":36,\"Trinadad&Tobago\":37,\"Peru\":38, \"Hong\":39,\"Holand-Netherland\":40}\n",
    "dict_data = {\"workclass\":dict_workclass,\"education\":dict_education,\"marital_status\":dict_marry,\"occupation\":dict_occ,\"relationship\":dict_relation,\"race\":dict_race,\"sex\":dict_sex,\"native_country\":dict_native_country}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class which implements the gaussian kernel function\n",
    "class RBF(object):\n",
    "    def __init__(self,gamma):\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self,X,Y=None):\n",
    "        XX = np.sum(X*X,axis=1)[:,np.newaxis]\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "            YY = np.transpose(XX)\n",
    "        else:\n",
    "            YY =  np.sum(Y*Y,axis=1)[np.newaxis,:]\n",
    "        dist = XX + YY\n",
    "        print(X.shape,Y.shape)\n",
    "        dist -= 2*np.dot(X,np.transpose(Y))\n",
    "        dist =  np.maximum(dist,0)\n",
    "        return np.exp(-self.gamma*dist)\n",
    "\n",
    "# Function implementing linear kernel\n",
    "def linear(X, Y=None):\n",
    "    \"\"\"Linear kernel\"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    return np.dot(X, np.transpose(Y))\n",
    "\n",
    "# Function implementing polynomial kernel\n",
    "class polynomial(object):\n",
    "    def __init__(self,q):\n",
    "        self.q = q\n",
    "    def __call__(self,X,Y=None):\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "        return (np.dot(X, np.transpose(Y))+1)**self.q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Multiple Kernel Method using heuristic methods to determine their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class which implements the multi-kernel function(convex sum of all the above kernels)\n",
    "# Also decides the weights heuristically\n",
    "class MultiKernelheuristic(object):\n",
    "    # Initializer for the class\n",
    "    def __init__(self,kernels,X=None):\n",
    "        self.kernels = kernels\n",
    "        self.X = X\n",
    "\n",
    "    # function which calculates gammas heuristically\n",
    "    def getGammas(self,X,Y):\n",
    "        nlist = list()\n",
    "        \n",
    "        y = np.dot(Y,Y.T)\n",
    "        for i in self.kernels:\n",
    "            k = i(X,Y)            \n",
    "            ai = np.sum(np.multiply(k,y))\n",
    "            aj = np.sum(np.multiply(k,k))\n",
    "            nlist.append(float(ai)/np.sqrt(aj))\n",
    "        c= sum(list(nlist))\n",
    "        # creating a list of gammas\n",
    "        b = [float(i)/c for i in nlist]\n",
    "        return b\n",
    "    \n",
    "    #method which is used while calling the class\n",
    "    def __call__(self, X, Y=None):\n",
    "\n",
    "        K = 0\n",
    "        if X is self.X and (Y is X or Y is None):\n",
    "            if self.flag == 1:\n",
    "                for gammas, Ki in zip(self.gamma,self.Ks):\n",
    "                    if gammas > 0.0:\n",
    "                        K += gammas * Ki\n",
    "        else:\n",
    "            if self.flag == 0:\n",
    "                self.gamma = self.getGammas(X,Y)\n",
    "                self.flag+=1\n",
    "            for gammas, kernel in zip(self.gamma,self.kernels):\n",
    "                if gammas > 0.0:\n",
    "                    K += gammas *kernel(X,Y)\n",
    "        return K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MultiKernelSVC class is actually refered from the github link given in the assignment description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class which implements the SVC for MultiKernel (fit() and predict() methods are implemented)\n",
    "class MultiKernelSVC(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,kernels,p=1,maxit=10,C=1,tol = 1e-5,store_objective=False):\n",
    "        self.kernels = kernels\n",
    "        self.p = p\n",
    "        self.maxit = maxit\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.store_objective = store_objective\n",
    "\n",
    "    def fit(self,X,y,**params):\n",
    "        p = float(self.p)\n",
    "        kernels = self.kernels\n",
    "        C= self.C\n",
    "\n",
    "        n_kernels = len(self.kernels)\n",
    "\n",
    "        multi_kernel = MultiKernelheuristic(kernels,X)\n",
    "\n",
    "        norms = np.empty(n_kernels)\n",
    "        maxit = self.maxit\n",
    "\n",
    "        # for it in range(maxit):\n",
    "        print(\"Running for iteration\")\n",
    "        svc = svm.SVC(kernel=multi_kernel,C=C)\n",
    "        print(\"Now fitting to the model\")\n",
    "        svc.fit(X,y)\n",
    "        print(\"Calculating dual_coef_ and support_\")\n",
    "        self._svc = svc\n",
    "\n",
    "    def predict(self,X):\n",
    "        return self._svc.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to map attribute values to the corresponding integers defined in the pre built dictionaries\n",
    "def encode_target(data,indices):\n",
    "    data2 = np.copy(data)\n",
    "    for i in indices:\n",
    "        for k in range(0,len(data)):\n",
    "            if data2[k][dict_columns[i]] != '?':\n",
    "                data2[k][dict_columns[i]] = str(dict_data[i][data2[k][dict_columns[i]]])\n",
    "            else:\n",
    "                x = random.randrange(0,len(dict_data[i]))\n",
    "                data2[k][dict_columns[i]] = str(x)\n",
    "    for i in range(0,14):\n",
    "        if list_columns[i] not in indices:\n",
    "            maxa = 0\n",
    "            mina = 9999999\n",
    "            for k in range(0,len(data2)):\n",
    "                if int(data2[k][i]) > maxa:\n",
    "                    maxa = int(data[k][i])\n",
    "                if int(data2[k][i]) < mina:\n",
    "                    mina = int(data[k][i])\n",
    "            print(\"\\n\")\n",
    "            for k in range(0,len(data)):\n",
    "                if int(data2[k][i]) >= mina and int(data2[k][i]) <= (maxa+4*mina)/5:\n",
    "                    data2[k][i] = \"0\"\n",
    "                elif int(data2[k][i]) >(maxa+4*mina)/5 and int(data2[k][i]) <= (2*maxa+3*mina)/5:\n",
    "                    data2[k][i] = \"1\"\n",
    "                elif int(data2[k][i]) >(2*maxa+3*mina)/5 and int(data2[k][i]) <= (3*maxa+2*mina)/5:\n",
    "                    data2[k][i] = \"2\"\n",
    "                elif int(data2[k][i]) >(3*maxa+2*mina)/5 and int(data2[k][i]) <= (4*maxa+1*mina)/5:\n",
    "                    data2[k][i] = \"3\"\n",
    "                elif int(data2[k][i]) >(4*maxa+1*mina)/5 and int(data2[k][i]) <= (5*maxa+0*mina)/5:\n",
    "                    data2[k][i] = \"4\"\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load data from a file\n",
    "def getData(filename):\n",
    "    data = []\n",
    "    special_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            x = line.split(\", \")\n",
    "            for i in [0,2,4,10,11,12,14]:\n",
    "                x[i] = int(x[i])\n",
    "            data.append(x)\n",
    "    data = np.array(data)\n",
    "    indices = [\"workclass\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native_country\"]\n",
    "    data = encode_target(data,indices)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function implementing cross validation split\n",
    "def cross_validation_split(dataset,n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset)/n_folds)\n",
    "    # rd.shuffle(dataset_copy)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size :\n",
    "            if len(dataset_copy) == 0:\n",
    "                break\n",
    "            index = random.randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function calculating accuracy  by comparing actual and predicted label list\n",
    "def getAccuracy(classval,result):\n",
    "    correct = 0\n",
    "    if len(classval) != len(result):\n",
    "        print(\"ERROR: Unequal Sizes of both arrays\")\n",
    "        print(str(len(classval)), str(len(result)))\n",
    "        return -0.01\n",
    "    for i in range(len(classval)):\n",
    "        if classval[i] == result[i]:\n",
    "            correct+=1\n",
    "    return correct / float(len(classval)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wrapper function which executed what we need\n",
    "def main():\n",
    "    data = getData(\"train.csv\")\n",
    "    data = data.astype(int)\n",
    "\n",
    "    #Cross_validated training returning data splitted in parts\n",
    "    folds = cross_validation_split(data,5)\n",
    "    scores = []\n",
    "    ii = 1\n",
    "    for fold in folds:\n",
    "        print(\"Fold: \"+str(ii))\n",
    "\n",
    "        # iterating over each fold in a five fold fashion\n",
    "        # selecting one fold as test data and others are grouped together as training data\n",
    "        ii+=1\n",
    "        train_set = list(folds)\n",
    "        train_set.pop(ii-2)\n",
    "        train_set = sum(train_set,[])\n",
    "        train_set=np.array(train_set)\n",
    "        train_set_values = train_set[:,-1]\n",
    "        train_set = train_set[:,[i for i in range(0,len(train_set[0])-1)]]\n",
    "        test_set = list()\n",
    "        actual = []\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            actual.append(row_copy[-1])\n",
    "            l = row_copy[0:len(row_copy)-1]\n",
    "            test_set.append(l)\n",
    "        C = 0.1\n",
    "        test_set = np.array(test_set)\n",
    "\n",
    "        # Using standard scaler to normalise the features\n",
    "        scaler = skp.StandardScaler()\n",
    "        train_set = scaler.fit_transform(train_set)\n",
    "        test_set = scaler.fit_transform(test_set)\n",
    "\n",
    "        # creating the multikernel\n",
    "        kernels = []\n",
    "        kernels.append(RBF(0.6))\n",
    "        kernels.append(linear)\n",
    "        kernels.append(polynomial(2))\n",
    "        \n",
    "        #training and predicting the labels as done by MultiKernelSVC\n",
    "        start = time.time()\n",
    "        clf = MultiKernelSVC(kernels=kernels,C=C,maxit=10,tol=1e-5,p=1,store_objective=True)\n",
    "        clf.fit(train_set,train_set_values)\n",
    "        end = time.time()\n",
    "        Z = clf.predict(test_set)\n",
    "        \n",
    "        #calculating accuracy\n",
    "        accuracy = getAccuracy(actual,Z)\n",
    "        print(\"Accuracy: \"+str(accuracy))\n",
    "        print(\"Time: \"+str(end-start)+\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of multikernel-heuristic is in CS15BTECH11044_svm notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
