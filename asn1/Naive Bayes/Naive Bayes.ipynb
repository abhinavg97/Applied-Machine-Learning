{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import  sklearn.metrics \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the train directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "spam_train_dir=\"/home/abhi/Desktop/Sem 5/AML/asn1/Naive Bayes/EmailsData/spam-train\"\n",
    "notspam_train_dir=\"/home/abhi/Desktop/Sem 5/AML/asn1/Naive Bayes/EmailsData/nonspam-train\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes class, contain custom and scikit implementations of the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Naive_bayes:\n",
    "    def __init__(self,spam_dir,non_spam_dir):\n",
    "        self.spam_dir=spam_dir\n",
    "        self.non_spam_dir=non_spam_dir\n",
    "        self.X_train=[]\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.select = SelectKBest(mutual_info_classif,50)\n",
    "    \n",
    "    # mathod to read the files in the train directory and making the train corpus\n",
    "    def _make_corpus(self):\n",
    "        files=[]\n",
    "        for file in os.listdir(self.spam_dir):\n",
    "            files += [self.spam_dir+'/'+file]\n",
    "        for file in os.listdir(self.non_spam_dir):\n",
    "            files+= [self.non_spam_dir+'/'+file]\n",
    "        for emails in files:\n",
    "            doc_string=\"\"\n",
    "            with open(emails) as email:\n",
    "                for line in email:\n",
    "                    doc_string = doc_string + line\n",
    "                if not self.X_train:\n",
    "                    self.X_train=[doc_string]\n",
    "                else:\n",
    "                    self.X_train.append(doc_string)\n",
    "    \n",
    "    # method to train the train corpus by using the tfidf values of the words in the train corpus\n",
    "    def train(self):\n",
    "        self._make_corpus()\n",
    "        self.Y_train = np.zeros(700)\n",
    "        self.Y_train[0:350] = 1\n",
    "        self.Y_train[350:700] = 0\n",
    "        # train_corpus_tf_idf contains a sparse matix of size 700 X number of unique words in the train corpus\n",
    "        # the value of each cell of the matrix is the tfidf value of the word for the train file\n",
    "        train_corpus_tf_idf = self.vectorizer.fit_transform(self.X_train)\n",
    "        # select_obj contains a numpy array of shape 700 X 50\n",
    "        # select k best selects k best features giving equal weights to both the classes while selecting them\n",
    "        # the values of the cells of the matrix are the same as that of tfidf train corpus matrix\n",
    "        self.select_obj = self.select.fit_transform(train_corpus_tf_idf.toarray(),self.Y_train)\n",
    "    \n",
    "    # method to calcualte mean and standard deviation for each feature from the select obj \n",
    "    # we calculate this for both the classes (i.e spam and not spam)\n",
    "    def mean_std(self):\n",
    "        spam_mean = np.mean(self.select_obj[:][0:350],axis=0)\n",
    "        # appending a small value to std to avoid division by zero errors\n",
    "        spam_std = np.std(self.select_obj[:][0:350],axis=0)+(10**(-6))  \n",
    "        notspam_mean = np.mean(self.select_obj[:][350:700],axis=0) \n",
    "        notspam_std = np.std(self.select_obj[:][350:700],axis=0)+(10**(-6))\n",
    "        return spam_mean,spam_std,notspam_mean,notspam_std\n",
    "            \n",
    "        \n",
    "    # method to predict the class of the test files\n",
    "    def predict(self,test_dir):\n",
    "        # files contain the path of all the test files to be tested\n",
    "        files=[]\n",
    "        X_test=[]\n",
    "    \n",
    "        for file in os.listdir(test_dir):\n",
    "            files += [test_dir+'/'+file]\n",
    "     # X_test conatins the data of each email in a seprate list\n",
    "        for emails in files:\n",
    "            doc_string=\"\"\n",
    "            with open(emails) as email:\n",
    "                for line in email:\n",
    "                    doc_string = doc_string + line\n",
    "                if not X_test:\n",
    "                    X_test=[doc_string]\n",
    "                else:\n",
    "                    X_test.append(doc_string)  \n",
    "        \n",
    "        #test_corpus_tf_idf is a sparse matrix of 260 X number of unique words present in the test corpus intersection number of unique words in the train corpus\n",
    "        # the value of each cell of the matrix is the tf idf value of the word for that file\n",
    "        test_corpus_tf_idf = self.vectorizer.transform(X_test)\n",
    "        # select test obj is a numpy array of shape 260 X (atmost 50 words )\n",
    "        select_test_obj = self.select.transform(test_corpus_tf_idf.toarray())\n",
    "        \n",
    "                        \n",
    "        spam=0\n",
    "        notspam=0\n",
    "        # calculating class mean and class std\n",
    "        spam_mean,spam_std,notspam_mean,notspam_std = self.mean_std()\n",
    "        # prediction array contains the predicted class for the test files\n",
    "        prediction=[]\n",
    "        \n",
    "        #for each test file predict its class\n",
    "        for row in select_test_obj:\n",
    "            # initaillizing spam and notspam prob. as 1\n",
    "            spam_prob=1\n",
    "            notspam_prob=1\n",
    "            \n",
    "            #for each word in the select_test_obj of the test file , calculating its spaminess\n",
    "            # and non spaminess(the probability of not spam if this word is present)\n",
    "            # we use gaussian of the word to calculate if it is likely to be spam or notspam\n",
    "            for i in range(len(row)):\n",
    "                spam_prob = spam_prob * np.e**((-(row[i]-spam_mean[i])**2)/(2*spam_std[i]*spam_std[i]))/(spam_std[i])\n",
    "            for i in range(len(row)):\n",
    "                notspam_prob = notspam_prob * np.e**((-(row[i]-notspam_mean[i])**2)/(2*notspam_std[i]*notspam_std[i]))/(notspam_std[i])\n",
    "            \n",
    "            \n",
    "            # predicting spam or not spam\n",
    "            if spam_prob>notspam_prob:\n",
    "                spam = spam+1\n",
    "                prediction.append(1)\n",
    "            else:\n",
    "                notspam = notspam+1\n",
    "                prediction.append(0)\n",
    "        \n",
    "        # returning prediction array\n",
    "        return prediction\n",
    "\n",
    "    # scikit implementation of naive bayes\n",
    "    def sklearrnpredict(self,test_dir):\n",
    "        files=[]\n",
    "        X_test=[]\n",
    "        for file in os.listdir(test_dir):\n",
    "            files += [test_dir+'/'+file]\n",
    "\n",
    "        for emails in files:\n",
    "            doc_string=\"\"\n",
    "            with open(emails) as email:\n",
    "                for line in email:\n",
    "                    doc_string = doc_string + line\n",
    "                if not X_test:\n",
    "                    X_test=[doc_string]\n",
    "                else:\n",
    "                    X_test.append(doc_string)  \n",
    "                \n",
    "        test_corpus_tf_idf = self.vectorizer.transform(X_test)\n",
    "        select_test_obj = self.select.transform(test_corpus_tf_idf.toarray())\n",
    "\n",
    "        clf = GaussianNB()\n",
    "        # fitting the train select obj , with the class labels using sklearn gaussian naive bayes\n",
    "        model = clf.fit(self.select_obj,self.Y_train)\n",
    "        # predicting the class of select test obj using sklearn predict\n",
    "        prediction = model.predict(select_test_obj)\n",
    "\n",
    "        spam = 0\n",
    "        notspam=0\n",
    "        for i in range(len(prediction)):\n",
    "            if prediction[i]==1:\n",
    "                spam=spam+1\n",
    "            else:\n",
    "                notspam = notspam+1\n",
    "        # returning prediction array\n",
    "        return prediction\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object to test Naive bayes methods implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test = Naive_bayes(spam_train_dir,notspam_train_dir)\n",
    "test.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing it using custom predict method on test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My accuracy =  0.965384615385\n",
      "F1 score =  0.966037735849\n",
      "Area under ROC curve =  0.965384615385\n",
      "Confusion Matrix :\n",
      "[[123   7]\n",
      " [  2 128]]\n"
     ]
    }
   ],
   "source": [
    "spam_test_dir=\"/home/abhi/Desktop/Sem 5/AML/asn1/Naive Bayes/EmailsData/spam-test\"\n",
    "notspam_test_dir=\"/home/abhi/Desktop/Sem 5/AML/asn1/Naive Bayes/EmailsData/nonspam-test\"\n",
    "\n",
    "prediction=[]\n",
    "prediction1=test.predict(spam_test_dir)\n",
    "prediction2=test.predict(notspam_test_dir)\n",
    "\n",
    "\n",
    "for i in prediction1:\n",
    "    prediction.append(i)\n",
    "for i in prediction2:\n",
    "    prediction.append(i)\n",
    "\n",
    "\n",
    "\n",
    "true=[1 for i in range(130)]\n",
    "for i in range(130):\n",
    "    true.append(0)\n",
    "\n",
    "print \"My accuracy = \",sklearn.metrics.accuracy_score(true, prediction)\n",
    "print \"F1 score = \",sklearn.metrics.f1_score(true, prediction)\n",
    "print \"Area under ROC curve = \",sklearn.metrics.roc_auc_score(true, prediction)\n",
    "print \"Confusion Matrix :\"\n",
    "print sklearn.metrics.confusion_matrix(true, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing it using the sklearn predict method on test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn accuracy =  0.969230769231\n",
      "F1 score =  0.969465648855\n",
      "Area under ROC curve =  0.969230769231\n",
      "Confusion Matrix :\n",
      "[[125   5]\n",
      " [  3 127]]\n"
     ]
    }
   ],
   "source": [
    "spam_test_dir=\"/home/abhi/Desktop/Sem 5/AML/asn1/Naive Bayes/EmailsData/spam-test\"\n",
    "notspam_test_dir=\"/home/abhi/Desktop/Sem 5/AML/asn1/Naive Bayes/EmailsData/nonspam-test\"\n",
    "\n",
    "prediction=[]\n",
    "prediction1=test.sklearrnpredict(spam_test_dir)\n",
    "prediction2=test.sklearrnpredict(notspam_test_dir)\n",
    "\n",
    "\n",
    "for i in prediction1:\n",
    "    prediction.append(i)\n",
    "for i in prediction2:\n",
    "    prediction.append(i)\n",
    "\n",
    "\n",
    "true=[1 for i in range(130)]\n",
    "for i in range(130):\n",
    "    true.append(0)\n",
    "print \"sklearn accuracy = \",sklearn.metrics.accuracy_score(true, prediction)\n",
    "print \"F1 score = \",sklearn.metrics.f1_score(true, prediction)\n",
    "print \"Area under ROC curve = \",sklearn.metrics.roc_auc_score(true, prediction)\n",
    "print \"Confusion Matrix :\"\n",
    "print sklearn.metrics.confusion_matrix(true, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "The accuracy for both the custom implementation and the built in implementation is almost the same(pretty good too!)\n",
    "\n",
    "## Observations\n",
    "\n",
    "Most of the emails of my implementation are correctly classified as observed from the confusion matrix.\n",
    "\n",
    "There are very few misclassifications for both my implementation and scikit implementation\n",
    "\n",
    "## A note on the libraries\n",
    "After training the selectk best object on the training dataset , it conviniently maps all the unique 50 words to cols.in the select_train_obj numpy array, this is good as , when we transform the tfidf sparse matrix to select_test_obj , we get the tfidf values of the same word in the mapped column.\n",
    "We then can perform evaluations on the spaminess of the word(feature)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
